1) Make it so that it reads the oldest database volume, checks if we have spare room in it and
incrementally add to that volume.
--> Choose to either increase the size of a database partition (ex. all database parititions were are
2GB, now we want them to be 4GB) or to just force the database to follow in suit of the original
parition size.
* I choose to follow the original partition size

2) Make an option for controlling the memory

3) Make it threaded

4) Update the wiki with the documentation for lastdb.

void generateDifference(const std::string &filename){

}

Make sure the prjs are correct for all scenarios of incremental formatting

Merging the volumes as they are constructed
Making sure that the database creation works in parallel (appendFromFasta, writing reading etc)

Think about how to handle the memory problem of 20GB. We can do it by writing every little partition
to disk in a proper format rather than handling it all at once.
We can use file pointers to concatenate properly!

Change all mentions of last and last+ to FAST.

If we have an ofstream with append, does that mean we are actually behind the scenes reading the
entire file in again?

How and when do I write out the full prj file to disk for the current partition?

What is the meaning behind the pad sizes?

How do I write the subset seeds for each partition

// There are two sources of potential extra bytes
From each thread
From each reinit
// Solution, start each file with a padsize and all the necessary paddings
// collapse reinit and init for appending into a single function so we are just
// always flushing the threads normally

Problem is the buckets. Why are the buckets so much smaller then we think they should be?